{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    SGDClassifier\n",
    ")\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "from tqdm import notebook \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python \n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отключение warning\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "#Формат float\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "# Сброс ограничений на число столбцов\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация прогресс-баров для apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Столбец 'Unnamed: 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   159,292.00\n",
       "mean     79,725.70\n",
       "std      46,028.84\n",
       "min           0.00\n",
       "25%      39,872.75\n",
       "50%      79,721.50\n",
       "75%     119,573.25\n",
       "max     159,450.00\n",
       "Name: Unnamed: 0, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Unnamed: 0'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['Unnamed: 0'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, что столбец 'Unnamed: 0' - лишний, он содержит просто номер сообщения.<br />\n",
    "Он не совпадает с индексами - видимо, это старый индекс. Похоже, часть сообщений была удалена, после чего индекс был сброшен.<br />\n",
    "Этот столбец не содержит полезной информации - стоит его удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Столбец 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                159292\n",
       "unique                                               159292\n",
       "top       Explanation\\nWhy the edits made under my usern...\n",
       "freq                                                      1\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец содержит текстовые сообщения. Пропуски отсутствуют, все сообщения уникальные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Столбец 'toxic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   159,292.00\n",
       "mean          0.10\n",
       "std           0.30\n",
       "min           0.00\n",
       "25%           0.00\n",
       "50%           0.00\n",
       "75%           0.00\n",
       "max           1.00\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.90\n",
       "1   0.10\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токсичных текстов - 10 %. Возможен перекос при обучении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбивка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop('toxic', axis = 1)\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=1176, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train.reset_index(drop=True)\n",
    "features_test = features_test.reset_index(drop=True)\n",
    "target_train = target_train.reset_index(drop=True)\n",
    "target_test = target_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.90\n",
       "1   0.10\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127433, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция очистки текстов постов:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ввожу функцию очищения текстов постов:\n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция лемматизации тектов Spacy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    disabled_pipes = [ \"parser\",  \"ner\"]\n",
    "    nlp = spacy.load('en_core_web_sm', disable=disabled_pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lem(text):\n",
    "    doc = nlp(text)\n",
    "    s = []\n",
    "    for token in doc:\n",
    "        s.append(token.lemma_)\n",
    "        s.append(token.pos_)\n",
    "    return(' '.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_batch_lem(texts,batch_size):\n",
    "    res = []\n",
    "    for i in notebook.tqdm(range((len(texts) // batch_size)+1)):\n",
    "        batch = texts[batch_size*i:batch_size*(i+1)]\n",
    "        merged_batch = \"|\".join(batch)\n",
    "        lemmed_batch = spacy_lem(merged_batch)\n",
    "        #res.append(pd.Series(lemmed_batch.split(sep=\"|\")))\n",
    "        for t in lemmed_batch.split(sep=\"|\"):\n",
    "            res.append(t)\n",
    "        #print(res)\n",
    "    return pd.Series(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Для трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 127433/127433 [00:05<00:00, 22317.50it/s]\n"
     ]
    }
   ],
   "source": [
    "features_train['ready_text'] = features_train['text'].progress_apply(clear_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72ed598c23b46678d03c56330ba86d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_train['lemm_text'] = spacy_batch_lem(features_train['ready_text'],batch_size).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 31859/31859 [00:01<00:00, 22933.65it/s]\n"
     ]
    }
   ],
   "source": [
    "features_test['ready_text'] = features_test['text'].progress_apply(clear_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5044e8fc76094781ae1551feedb3752f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_test['lemm_text'] = spacy_batch_lem(features_test['ready_text'],batch_size).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ready_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Their destructive nature that seems to destroy...</td>\n",
       "      <td>their destructive nature that seems to destroy...</td>\n",
       "      <td>their PRON destructive ADJ nature NOUN that PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obviously for a print work the verification of...</td>\n",
       "      <td>obviously for a print work the verification of...</td>\n",
       "      <td>obviously ADV for ADP a DET print NOUN work VE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\n\\n According to TV (History Channel?  NOVA?...</td>\n",
       "      <td>according to tv history channel nova the stove...</td>\n",
       "      <td>according NOUN to PART tv VERB history NOUN ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\n\\n Edit request from , 25 October 2011 \\n\\n...</td>\n",
       "      <td>edit request from october incorrect statement ...</td>\n",
       "      <td>edit NOUN request NOUN from ADP october PROPN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I do not care if you block me for stating a kn...</td>\n",
       "      <td>i do not care if you block me for stating a kn...</td>\n",
       "      <td>i NOUN do AUX not PART care VERB if SCONJ you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127428</th>\n",
       "      <td>\"\\n\\n 1947-48 Palestinian Civil War \\n\\n3 volu...</td>\n",
       "      <td>palestinian civil war volunteers worked hard t...</td>\n",
       "      <td>palestinian ADJ civil ADJ war NOUN volunteer N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127429</th>\n",
       "      <td>If you are going to edit this page, ADD to it,...</td>\n",
       "      <td>if you are going to edit this page add to it d...</td>\n",
       "      <td>if ADJ you PRON be AUX go VERB to PART edit VE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127430</th>\n",
       "      <td>YOU SHOULD NOT INTERFARE  \\n\\n(ranbir )\\ni thi...</td>\n",
       "      <td>you should not interfare ranbir i think you ar...</td>\n",
       "      <td>you NOUN should AUX not PART interfare VERB ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127431</th>\n",
       "      <td>The problem is that most other Senators don't ...</td>\n",
       "      <td>the problem is that most other senators don t ...</td>\n",
       "      <td>the DET problem NOUN be AUX that SCONJ most AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127432</th>\n",
       "      <td>\"\\n\\nHi Bobert60000, and Welcome to Wikipedia!...</td>\n",
       "      <td>hi bobert and welcome to wikipedia welcome to ...</td>\n",
       "      <td>hi PROPN bobert NOUN and CCONJ welcome ADJ to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127433 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       Their destructive nature that seems to destroy...   \n",
       "1       Obviously for a print work the verification of...   \n",
       "2       .\\n\\n According to TV (History Channel?  NOVA?...   \n",
       "3       \"\\n\\n Edit request from , 25 October 2011 \\n\\n...   \n",
       "4       I do not care if you block me for stating a kn...   \n",
       "...                                                   ...   \n",
       "127428  \"\\n\\n 1947-48 Palestinian Civil War \\n\\n3 volu...   \n",
       "127429  If you are going to edit this page, ADD to it,...   \n",
       "127430  YOU SHOULD NOT INTERFARE  \\n\\n(ranbir )\\ni thi...   \n",
       "127431  The problem is that most other Senators don't ...   \n",
       "127432  \"\\n\\nHi Bobert60000, and Welcome to Wikipedia!...   \n",
       "\n",
       "                                               ready_text  \\\n",
       "0       their destructive nature that seems to destroy...   \n",
       "1       obviously for a print work the verification of...   \n",
       "2       according to tv history channel nova the stove...   \n",
       "3       edit request from october incorrect statement ...   \n",
       "4       i do not care if you block me for stating a kn...   \n",
       "...                                                   ...   \n",
       "127428  palestinian civil war volunteers worked hard t...   \n",
       "127429  if you are going to edit this page add to it d...   \n",
       "127430  you should not interfare ranbir i think you ar...   \n",
       "127431  the problem is that most other senators don t ...   \n",
       "127432  hi bobert and welcome to wikipedia welcome to ...   \n",
       "\n",
       "                                                lemm_text  \n",
       "0       their PRON destructive ADJ nature NOUN that PR...  \n",
       "1       obviously ADV for ADP a DET print NOUN work VE...  \n",
       "2       according NOUN to PART tv VERB history NOUN ch...  \n",
       "3       edit NOUN request NOUN from ADP october PROPN ...  \n",
       "4       i NOUN do AUX not PART care VERB if SCONJ you ...  \n",
       "...                                                   ...  \n",
       "127428  palestinian ADJ civil ADJ war NOUN volunteer N...  \n",
       "127429  if ADJ you PRON be AUX go VERB to PART edit VE...  \n",
       "127430  you NOUN should AUX not PART interfare VERB ra...  \n",
       "127431  the DET problem NOUN be AUX that SCONJ most AD...  \n",
       "127432  hi PROPN bobert NOUN and CCONJ welcome ADJ to ...  \n",
       "\n",
       "[127433 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\simok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Расчет корпусов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = features_train['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test = features_test['lemm_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоги этапа:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загружен датасет, содержащий 159292 записи с текстами сообщений и их оценками. Наблюдается дисбаланс токсичных/нетоксичных комментариев, приблизительно 1:9\n",
    "2. Датасет содержит столбец со старыми индексами записей, 'Unnamed: 0'. Данный столбец удалён.\n",
    "3. Датасет был разбит на обучающую и тестовую выборку в пропорции 9:1.\n",
    "4. Произведена очистка сообщений от спецсимволов.\n",
    "5. Лемматизация сообщений не производилась из-за ее длительности\n",
    "6. Выделен ключевые признаки и корпуса сообщений для обучающей и тестовой выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В связи с дисбалансом классов, используем модели с параметром class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tqdm.sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipeLine для DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('clf', DummyClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_parameters = {\n",
    "    'clf__strategy':('stratified', 'prior', 'uniform', 'most_frequent'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(dummy_pipeline, \n",
    "                        dummy_parameters, \n",
    "                        n_iter = 5, \n",
    "                        scoring = 'f1',\n",
    "                        cv = 5, \n",
    "                        verbose = False, \n",
    "                        n_jobs=-1, \n",
    "                        random_state=1176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.8 s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time()\n",
    "rs.fit(corpus_train,target_train);\n",
    "dummy_time = time() - start\n",
    "dummy_score = rs.best_score_\n",
    "dummy_model = rs.best_estimator_\n",
    "dummy_params = rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1: 0.17\n",
      "Время подбора гиперпараметров: 91.99 сек.\n",
      "Гиперпараметры модели: {'clf__strategy': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print('Значение F1: {:.2f}'.format(dummy_score))\n",
    "print('Время подбора гиперпараметров: {:.2f} сек.'.format(dummy_time))\n",
    "print('Гиперпараметры модели:', dummy_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipeLine для LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('clf', LogisticRegression(random_state=1176, solver='liblinear', class_weight='balanced')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__norm': ('l1', 'l2'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(line_pipeline, \n",
    "                        line_parameters, \n",
    "                        n_iter = 5, \n",
    "                        scoring = 'f1',\n",
    "                        cv = 5, \n",
    "                        verbose = False, \n",
    "                        n_jobs=-1, \n",
    "                        random_state=1176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 23s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time()\n",
    "rs.fit(corpus_train,target_train);\n",
    "linear_time = time() - start\n",
    "linear_score = abs(rs.best_score_)\n",
    "linear_model = rs.best_estimator_\n",
    "linear_params = rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1: 0.74\n",
      "Время подбора гиперпараметров: 187.54 сек.\n",
      "Гиперпараметры модели: {'vect__norm': 'l2', 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print('Значение F1: {:.2f}'.format(linear_score))\n",
    "print('Время подбора гиперпараметров: {:.2f} сек.'.format(linear_time))\n",
    "print('Гиперпараметры модели:', linear_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipeLine для LogisticRegression со смещенным порогом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_2, features_valid_2, target_train_2, target_valid_2 = train_test_split(\n",
    "   corpus_train,target_train, test_size=0.2, random_state=1176, stratify = target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_pipeline_2 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('clf', LogisticRegression(random_state=1176, solver='liblinear', class_weight='balanced')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 23.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&quot;it&#x27;s&quot;, &#x27;he&#x27;, &#x27;too&#x27;, &quot;weren&#x27;t&quot;,\n",
       "                                             &#x27;above&#x27;, &#x27;was&#x27;, &#x27;themselves&#x27;,\n",
       "                                             &#x27;into&#x27;, &#x27;just&#x27;, &#x27;won&#x27;, &#x27;any&#x27;, &#x27;if&#x27;,\n",
       "                                             &quot;mightn&#x27;t&quot;, &#x27;once&#x27;, &#x27;where&#x27;, &#x27;out&#x27;,\n",
       "                                             &#x27;re&#x27;, &quot;wasn&#x27;t&quot;, &#x27;or&#x27;, &#x27;who&#x27;, &#x27;ll&#x27;,\n",
       "                                             &#x27;we&#x27;, &#x27;there&#x27;, &#x27;hadn&#x27;, &#x27;what&#x27;,\n",
       "                                             &#x27;doing&#x27;, &#x27;by&#x27;, &quot;should&#x27;ve&quot;,\n",
       "                                             &quot;isn&#x27;t&quot;, &#x27;all&#x27;, ...])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=1176,\n",
       "                                    solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&quot;it&#x27;s&quot;, &#x27;he&#x27;, &#x27;too&#x27;, &quot;weren&#x27;t&quot;,\n",
       "                                             &#x27;above&#x27;, &#x27;was&#x27;, &#x27;themselves&#x27;,\n",
       "                                             &#x27;into&#x27;, &#x27;just&#x27;, &#x27;won&#x27;, &#x27;any&#x27;, &#x27;if&#x27;,\n",
       "                                             &quot;mightn&#x27;t&quot;, &#x27;once&#x27;, &#x27;where&#x27;, &#x27;out&#x27;,\n",
       "                                             &#x27;re&#x27;, &quot;wasn&#x27;t&quot;, &#x27;or&#x27;, &#x27;who&#x27;, &#x27;ll&#x27;,\n",
       "                                             &#x27;we&#x27;, &#x27;there&#x27;, &#x27;hadn&#x27;, &#x27;what&#x27;,\n",
       "                                             &#x27;doing&#x27;, &#x27;by&#x27;, &quot;should&#x27;ve&quot;,\n",
       "                                             &quot;isn&#x27;t&quot;, &#x27;all&#x27;, ...])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=1176,\n",
       "                                    solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&quot;it&#x27;s&quot;, &#x27;he&#x27;, &#x27;too&#x27;, &quot;weren&#x27;t&quot;, &#x27;above&#x27;, &#x27;was&#x27;,\n",
       "                            &#x27;themselves&#x27;, &#x27;into&#x27;, &#x27;just&#x27;, &#x27;won&#x27;, &#x27;any&#x27;, &#x27;if&#x27;,\n",
       "                            &quot;mightn&#x27;t&quot;, &#x27;once&#x27;, &#x27;where&#x27;, &#x27;out&#x27;, &#x27;re&#x27;, &quot;wasn&#x27;t&quot;,\n",
       "                            &#x27;or&#x27;, &#x27;who&#x27;, &#x27;ll&#x27;, &#x27;we&#x27;, &#x27;there&#x27;, &#x27;hadn&#x27;, &#x27;what&#x27;,\n",
       "                            &#x27;doing&#x27;, &#x27;by&#x27;, &quot;should&#x27;ve&quot;, &quot;isn&#x27;t&quot;, &#x27;all&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=1176,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(stop_words=[\"it's\", 'he', 'too', \"weren't\",\n",
       "                                             'above', 'was', 'themselves',\n",
       "                                             'into', 'just', 'won', 'any', 'if',\n",
       "                                             \"mightn't\", 'once', 'where', 'out',\n",
       "                                             're', \"wasn't\", 'or', 'who', 'll',\n",
       "                                             'we', 'there', 'hadn', 'what',\n",
       "                                             'doing', 'by', \"should've\",\n",
       "                                             \"isn't\", 'all', ...])),\n",
       "                ('clf',\n",
       "                 LogisticRegression(class_weight='balanced', random_state=1176,\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "line_pipeline_2.fit(features_train_2, target_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "probabilities_valid = line_pipeline_2.predict_proba(features_valid_2)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "linear_2_score = 0\n",
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold # < напишите код здесь >\n",
    "    f1 = f1_score(target_valid_2,predicted_valid) # < напишите код здесь >\n",
    "    if f1 > linear_2_score:\n",
    "        linear_2_score = f1\n",
    "        best_trh = threshold\n",
    "linear_2_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1: 0.78 при пороге = 0.68\n",
      "Время подбора гиперпараметров: 3.62 сек.\n"
     ]
    }
   ],
   "source": [
    "print('Значение F1: {:.2f} при пороге = {:.2f}'.format(linear_2_score, best_trh))\n",
    "print('Время подбора гиперпараметров: {:.2f} сек.'.format(linear_2_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipeLine для SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно scikit-learn.org:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iterate = 10**6 // len(corpus_train)+1\n",
    "max_iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('clf', SGDClassifier(max_iter=max_iterate, random_state=1176,class_weight='balanced')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'clf__penalty':('l1','l2','elasticnet'),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(sgd_pipeline, \n",
    "                        sgd_parameters, \n",
    "                        n_iter = 5, \n",
    "                        scoring = 'f1',\n",
    "                        cv = 5, \n",
    "                        verbose = False, \n",
    "                        n_jobs=-1, \n",
    "                        random_state=1176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 26 s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time()\n",
    "rs.fit(corpus_train,target_train);\n",
    "sgd_time = time() - start\n",
    "sgd_score = abs(rs.best_score_)\n",
    "sgd_model = rs.best_estimator_\n",
    "sgd_params = rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1: 0.72\n",
      "Время подбора гиперпараметров: 136.44 сек.\n",
      "Гиперпараметры модели: {'vect__ngram_range': (1, 1), 'clf__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print('Значение F1: {:.2f}'.format(sgd_score))\n",
    "print('Время подбора гиперпараметров: {:.2f} сек.'.format(sgd_time))\n",
    "print('Гиперпараметры модели:', sgd_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipeLine для LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('clf', LGBMClassifier(class_weight = 'balanced')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 51, stop = 151, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(start = 1, stop = 30, num = 5)]\n",
    "learning_rate = [0.25, 0.5, 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'clf__n_estimators': n_estimators,\n",
    "    'clf__max_depth':max_depth,\n",
    "    'clf__learning_rate': learning_rate,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__ngram_range': ((1, 1), (1, 2)),\n",
       " 'clf__n_estimators': [51, 62, 73, 84, 95, 106, 117, 128, 139, 151],\n",
       " 'clf__max_depth': [1, 8, 15, 22, 30],\n",
       " 'clf__learning_rate': [0.25, 0.5, 0.75]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(lgbm_pipeline, \n",
    "                        lgbm_parameters, \n",
    "                        n_iter = 5, \n",
    "                        scoring = 'f1',\n",
    "                        cv = 5, \n",
    "                        verbose = False, \n",
    "                        n_jobs=-1, \n",
    "                        random_state=1176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12min 22s\n",
      "Wall time: 25min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time()\n",
    "rs.fit(corpus_train,target_train);\n",
    "lgbm_time = time() - start\n",
    "lgbm_score = abs(rs.best_score_)\n",
    "lgbm_model = rs.best_estimator_\n",
    "lgbm_params = rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1: 0.75\n",
      "Время подбора гиперпараметров: 1546.09 сек.\n",
      "Гиперпараметры модели: {'vect__ngram_range': (1, 2), 'clf__n_estimators': 117, 'clf__max_depth': 22, 'clf__learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print('Значение F1: {:.2f}'.format(lgbm_score))\n",
    "print('Время подбора гиперпараметров: {:.2f} сек.'.format(lgbm_time))\n",
    "print('Гиперпараметры модели:', lgbm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоги этапа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший результат на обучающей выборке показала модель \"PipeLine для LogisticRegression со смещенным порогом\" с параметрами:\n",
      "Значение F1: 0.78 при пороге = 0.68\n",
      "Время подбора гиперпараметров: 3.62 сек.\n"
     ]
    }
   ],
   "source": [
    "print('Наилучший результат на обучающей выборке показала модель \"PipeLine для LogisticRegression со смещенным порогом\" с параметрами:')\n",
    "print('Значение F1: {:.2f} при пороге = {:.2f}'.format(linear_2_score, best_trh))\n",
    "print('Время подбора гиперпараметров: {:.2f} сек.'.format(linear_2_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Незначительно от неё отстаёт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"PipeLine для LightGBM\"\n",
      "Значение F1: 0.75\n",
      "Время подбора гиперпараметров: 1546.09 сек.\n",
      "Гиперпараметры модели: {'vect__ngram_range': (1, 2), 'clf__n_estimators': 117, 'clf__max_depth': 22, 'clf__learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print('\"PipeLine для LightGBM\"')\n",
    "print('Значение F1: {:.2f}'.format(lgbm_score))\n",
    "print('Время подбора гиперпараметров: {:.2f} сек.'.format(lgbm_time))\n",
    "print('Гиперпараметры модели:', lgbm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель \"PipeLine для SGDClassifier\" и \"PipeLine для LogisticRegression\" для решения данной задачи не подходят из-за невыполнения требования значения метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим наилучшую модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.78\n"
     ]
    }
   ],
   "source": [
    "probabilities_test = line_pipeline_2.predict_proba(corpus_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "predicted_test = probabilities_one_test > best_trh\n",
    "f1 = f1_score(target_test,predicted_test)\n",
    "print(\"F1 = {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. Наилучший результат на обучающей выборке показала модель \"Логистическая регрессия со смещенным порогом\"\n",
      "   Значение F1 при пороге = 0.68\n",
      "   - на обучающей выборке: 0.78\n",
      "   - на тестовой выборке: 0.78\n",
      "   Время подбора гиперпараметров: 187.54 сек.\n"
     ]
    }
   ],
   "source": [
    "print('  1. Наилучший результат на обучающей выборке показала модель \"Логистическая регрессия со смещенным порогом\"')\n",
    "print('   Значение F1 при пороге = {:.2f}'.format(best_trh))\n",
    "print('   - на обучающей выборке: {:.2f}'.format(linear_2_score))\n",
    "print('   - на тестовой выборке: {:.2f}'.format(f1))\n",
    "print('   Время подбора гиперпараметров: {:.2f} сек.'.format(linear_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Значение метрики F1 данной модели на обучающей и тестовой выборках выше требуемого значения 0.75, следовательно, данная модель подходит для \"боевого\" применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. При проведении предварительной лемматизации текста возможно улучшить значение метрики модели, но при этом ощутимо ухудшится время ее работы (а именно - время предварительной подготовки данных)."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 101,
    "start_time": "2023-04-06T08:12:09.351Z"
   },
   {
    "duration": 86,
    "start_time": "2023-04-06T08:16:09.382Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T08:28:24.072Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T08:28:24.333Z"
   },
   {
    "duration": 2633,
    "start_time": "2023-04-06T08:28:24.338Z"
   },
   {
    "duration": 28,
    "start_time": "2023-04-06T08:28:26.973Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-06T08:28:27.002Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-06T08:28:27.023Z"
   },
   {
    "duration": 19,
    "start_time": "2023-04-06T08:28:27.029Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T08:28:27.050Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-06T08:28:27.061Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-06T08:28:27.087Z"
   },
   {
    "duration": 223,
    "start_time": "2023-04-06T08:28:27.097Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T08:28:27.321Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-06T08:28:27.333Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-06T08:28:27.352Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-06T08:28:27.363Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-06T08:28:27.381Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-06T08:28:27.394Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-06T08:28:27.396Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-06T08:28:44.772Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-06T08:28:53.399Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-06T08:28:53.416Z"
   },
   {
    "duration": 1037,
    "start_time": "2023-04-06T08:28:53.821Z"
   },
   {
    "duration": 37,
    "start_time": "2023-04-06T08:28:54.860Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-06T08:28:54.900Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-06T08:28:54.920Z"
   },
   {
    "duration": 23,
    "start_time": "2023-04-06T08:28:54.943Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-06T08:28:54.968Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-06T08:28:54.985Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-06T08:28:55.005Z"
   },
   {
    "duration": 246,
    "start_time": "2023-04-06T08:28:55.016Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-06T08:28:55.264Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-06T08:28:55.276Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-06T08:28:55.283Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T08:28:55.292Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-06T08:28:55.304Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-06T08:28:55.350Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-06T08:28:55.351Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T08:31:34.805Z"
   },
   {
    "duration": 1923,
    "start_time": "2023-04-06T08:33:30.630Z"
   },
   {
    "duration": 1876,
    "start_time": "2023-04-06T08:33:38.256Z"
   },
   {
    "duration": 129,
    "start_time": "2023-04-06T08:33:46.999Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-06T08:34:33.095Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T08:35:35.310Z"
   },
   {
    "duration": 1271,
    "start_time": "2023-04-06T08:35:35.896Z"
   },
   {
    "duration": 30,
    "start_time": "2023-04-06T08:35:37.176Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-06T08:35:37.207Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-06T08:35:37.223Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-06T08:35:37.430Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-06T08:35:37.493Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T08:35:37.590Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-06T08:35:37.781Z"
   },
   {
    "duration": 239,
    "start_time": "2023-04-06T08:35:37.879Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T08:35:38.120Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-06T08:35:38.198Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-06T08:35:38.230Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-06T08:35:38.518Z"
   },
   {
    "duration": 64,
    "start_time": "2023-04-06T08:35:38.598Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-06T08:35:41.377Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-06T08:35:41.718Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-06T08:35:46.622Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-06T08:35:47.542Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-06T08:37:50.526Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-06T08:38:03.846Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-06T08:38:08.438Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T08:38:12.118Z"
   },
   {
    "duration": 29,
    "start_time": "2023-04-06T08:38:29.414Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-06T08:38:35.273Z"
   },
   {
    "duration": 23,
    "start_time": "2023-04-06T08:38:38.073Z"
   },
   {
    "duration": 1099,
    "start_time": "2023-04-06T08:38:52.278Z"
   },
   {
    "duration": 632,
    "start_time": "2023-04-06T08:39:05.268Z"
   },
   {
    "duration": 1595,
    "start_time": "2023-04-06T08:39:07.511Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-06T08:39:45.510Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-06T08:39:50.614Z"
   },
   {
    "duration": 1286,
    "start_time": "2023-04-06T11:08:13.568Z"
   },
   {
    "duration": 1215,
    "start_time": "2023-04-06T11:15:22.758Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-06T11:15:23.974Z"
   },
   {
    "duration": 3441,
    "start_time": "2023-04-06T11:15:23.979Z"
   },
   {
    "duration": 26,
    "start_time": "2023-04-06T11:15:27.422Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-06T11:15:27.450Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T11:15:27.468Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T11:15:27.472Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-06T11:15:27.483Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T11:15:27.490Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-06T11:15:27.502Z"
   },
   {
    "duration": 246,
    "start_time": "2023-04-06T11:15:27.512Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-06T11:15:27.759Z"
   },
   {
    "duration": 29,
    "start_time": "2023-04-06T11:15:27.775Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-06T11:15:27.806Z"
   },
   {
    "duration": 25,
    "start_time": "2023-04-06T11:15:27.824Z"
   },
   {
    "duration": 117,
    "start_time": "2023-04-06T11:15:27.850Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-06T11:15:27.969Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-06T11:15:27.978Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-06T11:15:27.988Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-06T11:15:28.014Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-06T11:15:28.025Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-06T11:15:28.038Z"
   },
   {
    "duration": 3367,
    "start_time": "2023-04-06T11:15:28.057Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-06T11:15:31.426Z"
   },
   {
    "duration": 33,
    "start_time": "2023-04-06T11:15:31.429Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-06T11:15:31.464Z"
   },
   {
    "duration": 464,
    "start_time": "2023-04-06T11:15:31.486Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T11:15:31.953Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-06T11:15:31.958Z"
   },
   {
    "duration": 221,
    "start_time": "2023-04-06T11:15:31.984Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-06T11:15:32.207Z"
   },
   {
    "duration": 22,
    "start_time": "2023-04-06T11:15:32.211Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-06T11:15:32.234Z"
   },
   {
    "duration": 5545,
    "start_time": "2023-04-06T11:15:32.244Z"
   },
   {
    "duration": 5302,
    "start_time": "2023-04-06T11:15:37.790Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-06T11:15:43.094Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-06T11:15:43.099Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T11:15:43.109Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-06T11:15:43.120Z"
   },
   {
    "duration": 561,
    "start_time": "2023-04-06T11:15:43.127Z"
   },
   {
    "duration": 497,
    "start_time": "2023-04-06T11:15:43.689Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T11:15:44.188Z"
   },
   {
    "duration": 77894,
    "start_time": "2023-04-06T11:15:44.193Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T11:17:02.089Z"
   },
   {
    "duration": 68,
    "start_time": "2023-04-06T11:17:02.093Z"
   },
   {
    "duration": 12122,
    "start_time": "2023-04-06T11:17:02.162Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T11:17:14.285Z"
   },
   {
    "duration": 236996,
    "start_time": "2023-04-06T11:17:14.290Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-06T11:21:11.287Z"
   },
   {
    "duration": 179,
    "start_time": "2023-04-07T11:29:42.698Z"
   },
   {
    "duration": 115,
    "start_time": "2023-04-07T11:32:51.398Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
